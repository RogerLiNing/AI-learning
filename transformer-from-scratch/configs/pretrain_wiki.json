{
    "tokenizer_dir": "data/hf_tokenizer",
    "train_data_path": "data/raw/wikipedia-cn-20230720-filtered.json",
    "val_data_path": "data/processed/wikipedia-cn-20230720-filtered.json",
    "source_field": null,
    "completion_field": null,
    "text_field": "completion",
    
    "// 模型结构参数": "",
    "d_model": 768,
    "n_layers": 8,
    "n_heads": 12,
    "d_ff": 3072,
    "dropout": 0.1,
    "tie_weights": true,
    
    "// 序列和批次参数": "",
    "max_length": 512,
    "max_seq_len": 512,
    "vocab_size": 21132,
    "batch_size": 128,
    
    "// 数据加载优化": "",
    "num_workers": 28,
    "pin_memory": true,
    "prefetch_factor": 16,
    
    "// 训练优化参数": "",
    "lr": 5e-4,
    "weight_decay": 0.01,
    "warmup_ratio": 0.05,
    "lr_scheduler": "cosine",
    "gradient_accumulation_steps": 2,
    "gradient_checkpointing": true,
    
    "// 训练流程参数": "",
    "epochs": 3,
    "num_epochs": 3,
    "max_samples": 100000,
    "data_sampling_seed": 42,
    "truncate_long_sequences": true,
    "save_every": 5000,
    "eval_every": 1000,
    "use_amp": true,
    
    "// 内存优化": "",
    "memory_efficient_attention": true,
    "checkpoint_activation": false,
    "use_flash_attention": true,
    "use_bf16": true,
    "logging_steps": 100,
    "save_steps": 1000,
    "eval_steps": 500,
    "save_dir": "saved_models/wiki_pretrain"
}
