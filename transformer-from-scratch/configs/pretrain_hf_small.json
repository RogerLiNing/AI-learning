{
  "tokenizer_dir": "data/hf_tokenizer",
  "train_data_path": "data/processed/dialogue_conversation_train.txt",
  "val_data_path": "data/processed/dialogue_conversation_val.txt",
  "save_dir": "saved_models/pretrain_hf_small",
  "log_dir": "logs/pretrain_hf_small",
  
  "d_model": 512,
  "n_layers": 6,
  "n_heads": 8,
  "d_ff": 2048,
  "dropout": 0.1,
  "max_seq_len": 512,
  
  "batch_size": 32,
  "num_epochs": 5,
  "learning_rate": 5e-5,
  "weight_decay": 0.01,
  "warmup_ratio": 0.1,
  "gradient_accumulation_steps": 1,
  
  "logging_steps": 20,
  "save_steps": 100,
  "eval_steps": 50,
  
  "num_workers": 4,
  
  "max_train_samples": 5000,
  "max_val_samples": 500
}
